{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Kinematics Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Feb  7 09:23:56 2024\n",
    "\n",
    "@author: parallel\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def invKin(pos):\n",
    "    \"\"\"\n",
    "    enter x, y, z and output theta vector \n",
    "    \n",
    "    \"\"\"\n",
    "    # define robot dimentions\n",
    "    x, y, z = pos[0], pos[1], pos[2]\n",
    "    w_b = 80\n",
    "    s_b = 277.128\n",
    "    u_b = 160\n",
    "\n",
    "    w_p = 15.16\n",
    "    s_p = 52.5\n",
    "    u_p = 30.31\n",
    "\n",
    "    L = 120\n",
    "    l = 340\n",
    "    h = 55\n",
    "    \n",
    "    # define parameters\n",
    "    a = w_b - u_p\n",
    "    b = s_p / 2 - (np.sqrt(3)/2) * w_b\n",
    "    c = w_p - w_b / 2\n",
    "    \n",
    "    # calc\n",
    "    E1 = 2*L*(y+a)\n",
    "    F1 = 2*z*L\n",
    "    G1 = x**2 + y**2 + z**2 + a**2 + L**2 + 2*y*a - l**2\n",
    "    \n",
    "    E2 = -L*(np.sqrt(3) * (x+b) + y + c)\n",
    "    F2 = 2*z*L\n",
    "    G2 = x**2 + y**2 + z**2 + b**2 + c**2 + L**2 + 2*(x*b + y*c) - l**2\n",
    "    \n",
    "    E3 = L*(np.sqrt(3)*(x-b)-y-c)\n",
    "    F3 = 2*z*L\n",
    "    G3 = x**2 + y**2 + z**2 + b**2 + c**2 + L**2 + 2*(-x*b + y*c) - l**2\n",
    "    \n",
    "    t1_p = (-F1 + np.sqrt(E1**2 + F1**2 - G1**2)) / (G1 - E1)\n",
    "    t1_m = (-F1 - np.sqrt(E1**2 + F1**2 - G1**2)) / (G1 - E1)\n",
    "    t2_p = (-F2 + np.sqrt(E2**2 + F2**2 - G2**2)) / (G2 - E2)\n",
    "    t2_m = (-F2 - np.sqrt(E2**2 + F2**2 - G2**2)) / (G2 - E2)\n",
    "    t3_p = (-F3 + np.sqrt(E3**2 + F3**2 - G3**2)) / (G3 - E3)\n",
    "    t3_m = (-F3 - np.sqrt(E3**2 + F3**2 - G3**2)) / (G3 - E3) \n",
    "    \n",
    "    # get theta\n",
    "    theta1_p = 2*np.arctan2(t1_m*(G1 - E1), (G1 - E1))\n",
    "    theta2_p = 2*np.arctan2(t2_m*(G2 - E2), (G2 - E2))\n",
    "    theta3_p = 2*np.arctan2(t3_m*(G3 - E3), (G3 - E3))\n",
    "#    theta1_m = 2*np.arctan2(t1_m)\n",
    "#    theta1_m = 2*np.arctan2(t2_m)\n",
    "#    theta1_m = 2*np.arctan2(t3_m)\n",
    "\n",
    "        \n",
    "    theta = np.array([theta1_p, theta2_p, theta3_p]) * 180 / np.pi\n",
    "    \n",
    "    # make sure the range output is between -30 to 60 degrees.\n",
    "    for inx in range(3):\n",
    "        print(\"h\")\n",
    "        if theta[inx] >= 330 and theta[inx] <= 360: # correct part from -30 to 0\n",
    "            theta[inx] -= 360\n",
    "            \n",
    "        elif theta[inx] >= -360 and theta[inx] <= -300: # correct the part correesponding to 0 to 60\n",
    "            theta[inx] += 360\n",
    "        \n",
    "        \n",
    "        elif theta[inx] > 60 or theta[inx] < -30:\n",
    "            print(f\"theta vec is out of range - it is = {theta}\")\n",
    "            print(\"return to home because you suck\")\n",
    "            return [-30, -30, -30]\n",
    "    return theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate System Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_cage_to_base(cage_position):\n",
    "    \"\"\"\n",
    "    The location of base w.r.t cage coordinate system is:\n",
    "        x = 183\n",
    "        y = 262\n",
    "        z = 405\n",
    "    The rotation of base w.r.t cage coordinate system is:\n",
    "        61 degrees about z axis = 1.064650843716541 rad\n",
    "        -R_T@d = [140.43020277 -287.07552691 -405]\n",
    "    \"\"\"\n",
    "    ang = 1.064650843716541\n",
    "    \n",
    "    M = np.array([\n",
    "        [np.cos(ang), -np.sin(ang), 0, 140.43020277],\n",
    "        [np.sin(ang), np.cos(ang), 0, -287.07552691],\n",
    "        [0, 0, 1, -405],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    base_position = M @ np.array(cage_position + [1])\n",
    "    return base_position[:3]\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs_frame_to_cage(x, y, h, w):\n",
    "    x_mid = x + w/2 + 93\n",
    "    y_mid = - y + h/2 + 288\n",
    "    cage_coords_to_pick = [x_mid, y_mid, 20]\n",
    "    return cage_coords_to_pick\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Feb 14 09:36:01 2024\n",
    "\n",
    "@author: parallel\n",
    "\"\"\"\n",
    "\n",
    "# calibrate camera\n",
    "# Import required modules\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def capture_image():\n",
    "\n",
    "    #  Rotation Vectors:\n",
    "    # (array([[ 0.08488239],\n",
    "    #        [-0.00621647],\n",
    "    #        [-0.01404018]]),)\n",
    "\n",
    "    #  Translation Vectors:\n",
    "    # (array([[-11.94359699],\n",
    "    #        [ -0.39084338],\n",
    "    #        [ 48.83364547]]),)\n",
    "      \n",
    "    video = cv2.VideoCapture(0)\n",
    "    # get image from camera(corrent frame!)\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    matrix = np.array(\n",
    "        [[1.17673043e+03, 0.00000000e+00, 3.22412128e+02],\n",
    "         [0.00000000e+00, 1.18810840e+03, 1.74915728e+02],\n",
    "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
    "\n",
    "    distortion = np.array(\n",
    "        [[ 4.25806110e-01, -2.72307004e+00, -7.51942459e-03, -3.68742702e-03,\n",
    "          -5.69413505e+00]])\n",
    "\n",
    "\n",
    "    img = frame\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(matrix, distortion, (w,h), 1, (w,h))\n",
    "\n",
    "    # undistort\n",
    "    mapx, mapy = cv2.initUndistortRectifyMap(matrix, distortion, None, newcameramtx, (w,h), 5)\n",
    "    dst = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    cv2.imwrite('dst.png', dst)\n",
    "\n",
    "    # disconnect from camera\n",
    "    video.release()\n",
    "    \n",
    "    # # wait for a key event and close the windows\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()               \n",
    "                  \n",
    "    return 'dst.png'\n",
    "\n",
    "\n",
    "def find_block(filename, color):\n",
    "    image = cv2.imread(filename)\n",
    "\n",
    "    # # plot image \n",
    "    # cv2.imshow('Image', image)\n",
    "      \n",
    "    # change image format to HSV\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    if color == 'yellow':\n",
    "        lower = np.array([17, 141, 150])\n",
    "        upper = np.array([37, 255, 255])\n",
    "    elif color == 'blue':\n",
    "        lower = np.array([77, 177, 73])\n",
    "        upper = np.array([179, 255, 255])\n",
    "    elif color == 'green':\n",
    "        lower = np.array([34, 81, 0])\n",
    "        upper = np.array([61, 255, 255])\n",
    "    elif color == 'orange':\n",
    "        lower = np.array([0, 141, 150])\n",
    "        upper = np.array([15, 255, 255])\n",
    "    \n",
    "    # Create a mask for the color\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "\n",
    "    # check mask:\n",
    "    # cv2.imshow('mask', mask)\n",
    "    cv2.imwrite(f'Mask_{color}.png', mask)\n",
    "\n",
    "    # Find the contours in the mask\n",
    "    contours, _  = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    # Draw a rectangle around the contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image\n",
    "    # cv2.imshow('Image', image)\n",
    "    cv2.imwrite(f'Rect_{color}.png', image)\n",
    "    print(color)\n",
    "    print(\"h = \", h)\n",
    "    print(\"w = \", w)\n",
    "    print(\"x = \", x)\n",
    "    print(\"y = \", y)\n",
    "\n",
    "    return  x, y, w, h\n",
    "\n",
    "\n",
    "# find_block(capture_image(), 'yellow')\n",
    "# find_block(capture_image(), 'green')\n",
    "# find_block(capture_image(), 'blue')\n",
    "# find_block(capture_image(), 'orange')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
